{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "melanoma_pytorch_v6_with_metaData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1O2jNraOAYcZRLvskTwoi-VyQQ8ApPfXr",
      "authorship_tag": "ABX9TyNjWwl+KFMSj1R0EXvitNR+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aunabil4602/Kaggle-Competitions/blob/master/melanoma_pytorch_with_metaData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2DxKDMIzPa2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "e52cbf56-b7c3-4716-8778-32bef656b16f"
      },
      "source": [
        "!nvidia-smi -L\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-106ec296-521c-239f-ebfa-6d62dc8c55af)\n",
            "Mon Aug 17 14:54:36 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    31W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeT5fWeNOISF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "5e601190-d276-46dc-e89a-e6bccb6fafcb"
      },
      "source": [
        "!pip install -U git+https://github.com/albu/albumentations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/albu/albumentations\n",
            "  Cloning https://github.com/albu/albumentations to /tmp/pip-req-build-2guuiiwn\n",
            "  Running command git clone -q https://github.com/albu/albumentations /tmp/pip-req-build-2guuiiwn\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (4.4.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-cp36-none-any.whl size=66166 sha256=e9b685658d0bc153f4aa5063fcac3cdb3e0dd65fcb9513cfbdaa5a6daad4da61\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p2563i2f/wheels/45/8b/e4/2837bbcf517d00732b8e394f8646f22b8723ac00993230188b\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CFmoio6zVSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports \n",
        "\n",
        "import os \n",
        "import shutil \n",
        "import numpy as np \n",
        "from PIL import Image \n",
        "import PIL \n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd \n",
        "import math\n",
        "import time\n",
        "import sys\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torchvision\n",
        "import albumentations\n",
        "\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
        "\n",
        "torch.set_default_tensor_type('torch.FloatTensor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSBfsGy1iRGL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3e1c2ee1-f3d0-4689-9168-e91689925561"
      },
      "source": [
        "shutil.copy('/content/drive/My Drive/data_sets/Melanoma Data/ZipData/train_540.zip','training.zip')\n",
        "shutil.copy('/content/drive/My Drive/data_sets/Melanoma Data/ZipData/hairs.zip','hairs.zip')\n",
        "shutil.copy('/content/drive/My Drive/data_sets/Melanoma Data/ZipData/extra_melanoma_540.zip','extra.zip')\n",
        "shutil.copy('/content/drive/My Drive/data_sets/Melanoma Data/ZipData/train_meta_v1.csv','./meta_data.csv')\n",
        "\n",
        "os.mkdir('train')\n",
        "os.mkdir('hairs')\n",
        "\n",
        "#importing training set\n",
        "shutil.unpack_archive('training.zip','train','zip')\n",
        "shutil.unpack_archive('hairs.zip','hairs','zip')\n",
        "shutil.unpack_archive('extra.zip','./','zip')\n",
        "\n",
        "csv_v1=pd.read_csv('meta_data.csv')\n",
        "print(len(csv_v1))\n",
        "\n",
        "\n",
        "temp_list=os.listdir('resized_540')\n",
        "for name in temp_list:\n",
        "  shutil.move('resized_540/'+name,'train/'+name)\n",
        "\n",
        "all_images=os.listdir('train')\n",
        "for name in all_images:\n",
        "    if name[:5]=='M_IMG':\n",
        "        os.remove('train/'+name)\n",
        "\n",
        "\n",
        "all_normal=[]\n",
        "all_melanoma=[]\n",
        "cnt=0\n",
        "for it,val in enumerate(csv_v1['target']):\n",
        "\n",
        "    if val==0:\n",
        "        all_normal.append(it)\n",
        "        cnt+=1\n",
        "    else :\n",
        "        all_melanoma.append(it)\n",
        "        \n",
        "print(len(os.listdir('train')))\n",
        "print('Total Malignant: ',len(all_normal))\n",
        "print('Total Melanoma: ',len(all_melanoma))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37648\n",
            "37648\n",
            "Total Malignant:  32542\n",
            "Total Melanoma:  5106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afveRBWn6bP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "89a03d9c-096c-474e-b9a1-ca122fb57dd0"
      },
      "source": [
        "csv_v1=pd.read_csv('meta_data.csv')\n",
        "print(len(csv_v1))\n",
        "\n",
        "all_normal=[]\n",
        "all_melanoma=[]\n",
        "cnt=0\n",
        "for it,val in enumerate(csv_v1['target']):\n",
        "\n",
        "    if val==0:\n",
        "        all_normal.append(it)\n",
        "        cnt+=1\n",
        "    else :\n",
        "        all_melanoma.append(it)\n",
        "        \n",
        "print(len(os.listdir('train')))\n",
        "print('Total Malignant: ',len(all_normal))\n",
        "print('Total Melanoma: ',len(all_melanoma))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37648\n",
            "37648\n",
            "Total Malignant:  32542\n",
            "Total Melanoma:  5106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLKY9d7UoKma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6018c793-085c-417e-abdf-edea03a9974c"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
        "cpu_device = torch.device(\"cpu\") \n",
        "print(device) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfByrF3C-tao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size=300\n",
        "\n",
        "class MelanomaDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, data_,index_,is_train=True):\n",
        "        self.dataframe = data_\n",
        "        self.main_list=index_\n",
        "        if is_train:\n",
        "            self.transform = albumentations.core.composition.Compose([\n",
        "                albumentations.augmentations.transforms.RandomResizedCrop(height=img_size, width=img_size, scale=(0.4, 1.0),p=1.0),\n",
        "                albumentations.augmentations.transforms.ShiftScaleRotate(rotate_limit=90.0,shift_limit=0.0,scale_limit=0.0,p=1.0),\n",
        "                albumentations.augmentations.transforms.HorizontalFlip(p=0.5),\n",
        "                albumentations.augmentations.transforms.VerticalFlip(p=0.5),\n",
        "                albumentations.augmentations.transforms.HueSaturationValue(hue_shift_limit=20,sat_shift_limit=20,val_shift_limit=20,p=1.0),\n",
        "                albumentations.augmentations.transforms.RandomBrightnessContrast(brightness_limit=0.3,contrast_limit= 0.3,p=1.0),\n",
        "                albumentations.augmentations.transforms.FancyPCA(alpha=0.1,p=1.0),\n",
        "                AdvancedHairAugmentation(p=0.5),\n",
        "                albumentations.augmentations.transforms.Cutout(num_holes=10, max_h_size=10, max_w_size=10, p=0.5),\n",
        "                albumentations.augmentations.transforms.Normalize(),\n",
        "                albumentations.pytorch.transforms.ToTensorV2(),\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = albumentations.core.composition.Compose([ \n",
        "                albumentations.augmentations.transforms.Resize(height=344, width=344), \n",
        "                albumentations.augmentations.transforms.CenterCrop(height=img_size, width=img_size),                                                     \n",
        "                albumentations.augmentations.transforms.Normalize(), \n",
        "                albumentations.pytorch.transforms.ToTensorV2(),\n",
        "            ])\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.main_list)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        index=self.main_list[index]\n",
        "        #print('lol')\n",
        "        label=self.dataframe['target'][index]\n",
        "        #print('lol')\n",
        "        name = self.dataframe['image_name'][index]\n",
        "\n",
        "        if name[0]=='M' or name[0]=='N':\n",
        "            if label==0:\n",
        "                name='N'+name[1:]\n",
        "            else :\n",
        "                name='M'+name[1:]\n",
        "        #print('lol')\n",
        "        image = cv2.imread('train/'+name,cv2.IMREAD_UNCHANGED)   \n",
        "        #print(name,label,type(image))\n",
        "        image = self.transform(image=image)\n",
        "        image = image['image']\n",
        "\n",
        "        csv_data = np.array(self.dataframe.iloc[index][['torso','upper extremity','lower extremity',\n",
        "                                                       'head/neck','palms/soles','oral/genital','sex', 'age']].values, \n",
        "                            dtype=np.float32)\n",
        "        csv_data[-1]=(csv_data[-1]-50.2762)/15.0\n",
        "        #print('lol')\n",
        "        return image,csv_data,label\n",
        "\n",
        "\n",
        "\n",
        "class AdvancedHairAugmentation(ImageOnlyTransform):\n",
        "    def __init__(self, hairs: int = 10, hairs_folder: str = \"hairs\" , always_apply=False, p=0.5):\n",
        "      self.hairs = hairs\n",
        "      self.hairs_folder = hairs_folder\n",
        "      super().__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, img, **params):\n",
        "        n_hairs = random.randint(0, self.hairs)+5\n",
        "\n",
        "        if not n_hairs:\n",
        "            return img\n",
        "\n",
        "        height, width, _ = img.shape  # target image width and height\n",
        "        hair_images = [im for im in os.listdir(self.hairs_folder) if 'png' in im]\n",
        "\n",
        "        for _ in range(n_hairs):\n",
        "            hair = cv2.imread(os.path.join(self.hairs_folder, random.choice(hair_images)))\n",
        "            hair = cv2.flip(hair, random.choice([-1, 0, 1]))\n",
        "            hair = cv2.rotate(hair, random.choice([0, 1, 2]))\n",
        "\n",
        "            h_height, h_width, _ = hair.shape  # hair image width and height\n",
        "            roi_ho = random.randint(0, img.shape[0] - hair.shape[0])\n",
        "            roi_wo = random.randint(0, img.shape[1] - hair.shape[1])\n",
        "            roi = img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width]\n",
        "\n",
        "            img2gray = cv2.cvtColor(hair, cv2.COLOR_BGR2GRAY)\n",
        "            ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
        "            mask_inv = cv2.bitwise_not(mask)\n",
        "            img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
        "            hair_fg = cv2.bitwise_and(hair, hair, mask=mask)\n",
        "\n",
        "            dst = cv2.add(img_bg, hair_fg, dtype=cv2.CV_64F)\n",
        "            img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width] = dst\n",
        "\n",
        "        return img\n",
        "\n",
        "img_wh=img_size\n",
        "centre=(img_wh-1)/2.0\n",
        "rad=(img_wh-2)/2.0\n",
        "out_x=[]\n",
        "out_y=[]\n",
        "\n",
        "for x in range(img_wh):\n",
        "  for y in range(img_wh):\n",
        "    dis=math.sqrt((x-centre)*(x-centre)+(y-centre)*(y-centre))\n",
        "    if dis>rad:\n",
        "      out_x.append(x)\n",
        "      out_y.append(y)\n",
        "out_x=tuple(np.asarray(out_x))\n",
        "out_y=tuple(np.asarray(out_y))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp4cv7p7ozGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "55f9b046-4eb3-448e-a8da-50e7bb587588"
      },
      "source": [
        "#model\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSNSfDzo47iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Identity(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "class CNN_Meta_NET(torch.nn.Module):\n",
        "    def __init__(self, model_name, input_size,output_size):\n",
        "        super().__init__()\n",
        "        self.input_size, self.output_size = input_size, output_size\n",
        "        \n",
        "        self.model_name=model_name\n",
        "        self.cnn = EfficientNet.from_pretrained(self.model_name,num_classes=1)\n",
        "        self.cnn._fc=Identity()\n",
        "        for param in self.cnn.parameters():\n",
        "            param.requires_grad=False\n",
        "\n",
        "        self.meta = torch.nn.Sequential(torch.nn.Linear(self.input_size, 200),\n",
        "                                 torch.nn.BatchNorm1d(200),\n",
        "                                 torch.nn.ReLU(),\n",
        "                                 torch.nn.Dropout(p=0.2))\n",
        "\n",
        "        self.classification = torch.nn.Linear(1536 + 200, self.output_size) \n",
        "        \n",
        "    def forward(self, image, meta_data, prints=False):    \n",
        "        \n",
        "        cnn_out = self.cnn(image)\n",
        "        meta_out = self.meta(meta_data)\n",
        "        \n",
        "        cnn_meta_out = torch.cat((cnn_out, meta_out), dim=1)\n",
        "        final_out = self.classification(cnn_meta_out)\n",
        "        \n",
        "        return final_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfzFAKtgo6Ih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b96b824e-bb13-4240-eaca-f9f1fd4d3e55"
      },
      "source": [
        "# setting up model and scheduler\n",
        "\n",
        "model_name='efficientnet-b3'\n",
        "model = CNN_Meta_NET(model_name,8,1)\n",
        "model=model.to(device)\n",
        "\n",
        "lr_patience=1\n",
        "lr_factor=0.1\n",
        "b_size=16\n",
        "starting_lr=0.1*b_size/256\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=starting_lr, momentum=0.9,weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max',patience=lr_patience,min_lr=1e-9, verbose=True, factor=lr_factor)\n",
        "\n",
        "print(model_name)\n",
        "print('batch size: ',b_size,' , lr: ',starting_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b3\n",
            "efficientnet-b3\n",
            "batch size:  16  , lr:  0.00625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JniTpXBJo9_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ae2da32-5411-421f-fb0c-c898a583b567"
      },
      "source": [
        "\n",
        "number_of_folds = 4\n",
        "num_move_normal=int(len(all_normal)/number_of_folds)\n",
        "num_move_melanoma=int(len(all_melanoma)/number_of_folds)\n",
        "epochs=15\n",
        "print(num_move_melanoma,num_move_normal)\n",
        "\n",
        "\n",
        "for itr_folds in range(4):\n",
        "    print('------------Running Fold no: ',itr_folds+1,'------------')\n",
        " \n",
        "\n",
        "    ## setting test images\n",
        "    cnt_mel,cnt_nor= 0,0\n",
        "    test_data_idx,train_data_idx=[],[]\n",
        "    for it in range(itr_folds*num_move_normal,(itr_folds==(number_of_folds-1))*len(all_normal)+(itr_folds!=(number_of_folds-1))*(itr_folds+1)*num_move_normal):\n",
        "        test_data_idx.append(all_normal[it])\n",
        "\n",
        "    for it in range(itr_folds*num_move_melanoma,(itr_folds==(number_of_folds-1))*len(all_melanoma)+(itr_folds!=(number_of_folds-1))*(itr_folds+1)*num_move_melanoma):\n",
        "        test_data_idx.append(all_melanoma[it])\n",
        "\n",
        "    ## setting training images\n",
        "    for it in range(0,itr_folds*num_move_normal):\n",
        "        cnt_nor+=1\n",
        "        train_data_idx.append(all_normal[it])\n",
        "\n",
        "    for times in range(6):\n",
        "        for it in range(0,itr_folds*num_move_melanoma):\n",
        "            cnt_mel+=1\n",
        "            train_data_idx.append(all_melanoma[it])\n",
        "\n",
        "    for it in range((itr_folds==(number_of_folds-1))*len(all_normal)+(itr_folds!=(number_of_folds-1))*(itr_folds+1)*num_move_normal,len(all_normal)):\n",
        "        cnt_nor+=1\n",
        "        train_data_idx.append(all_normal[it])\n",
        "\n",
        "    for times in range(6):\n",
        "        for it in range((itr_folds==(number_of_folds-1))*len(all_melanoma)+(itr_folds!=(number_of_folds-1))*(itr_folds+1)*num_move_melanoma,len(all_melanoma)):\n",
        "            cnt_mel+=1\n",
        "            train_data_idx.append(all_melanoma[it])\n",
        "\n",
        "    print('Train Size :',len(train_data_idx),' (nor: {:d} ,mel: {:d})'.format(cnt_nor,cnt_mel),' Test Size : ',len(test_data_idx))\n",
        "\n",
        "    # setting up train and test dataloader\n",
        "    train_data = MelanomaDataset(csv_v1,train_data_idx,is_train=True)                                                                                   \n",
        "    train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=b_size, shuffle=True,  num_workers=4)\n",
        "\n",
        "    test_data = MelanomaDataset(csv_v1,test_data_idx,is_train=False)\n",
        "    test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=b_size, shuffle=True, num_workers=4)\n",
        "    \n",
        "    ##train and validation\n",
        "    stop_patience=3\n",
        "    best_val_spec=0.0\n",
        "    \n",
        "    \n",
        "    for ep in range(epochs):\n",
        "    \n",
        "        ##train single epoch\n",
        "        state='train'\n",
        "        acc=0.0\n",
        "        running_loss = 0.0\n",
        "\n",
        "        val_spec=0.0\n",
        "        avg_time=0.0\n",
        "        st_time=time.time()\n",
        "\n",
        "        num_correct=0.0\n",
        "        total_guesses=0.0\n",
        "        model.train()\n",
        "        for i, batch_data in enumerate(train_data_loader, 0):   \n",
        "\n",
        "            inputs,meta_, labels = batch_data\n",
        "            if inputs.size()[0]<=1:\n",
        "                break\n",
        "\n",
        "            #break\n",
        "            labels = labels.type(torch.FloatTensor)\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            meta_ = meta_.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(inputs,meta_)\n",
        "            outputs=outputs.squeeze(1)\n",
        "\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step() \n",
        "\n",
        "            outputs= torch.sigmoid(outputs)\n",
        "            num_correct += torch.eq(torch.round(outputs), labels).sum().item()\n",
        "            total_guesses += inputs.size()[0] \n",
        "            running_loss += loss.item()\n",
        "\n",
        "            print('\\rTime: [{:.3f}]s, Epoch: [{:d}/{:d}], Batch: [{:d}/{:d}], Loss: [{:.7f}], Acc: [{:.7f}]'.format(time.time()-st_time,(ep+1),epochs,(i+1),len(train_data_loader),running_loss/(i+1),1.0*num_correct/np.maximum(total_guesses,1.0)),end='',flush=True)\n",
        "        \n",
        "        #break\n",
        "        print('')\n",
        "        acc=1.0*num_correct/np.maximum(total_guesses,1.0)\n",
        "        running_loss/=(i+1)\n",
        "\n",
        "        #validation \n",
        "        state='test'\n",
        "        v_acc=0.0\n",
        "        v_running_loss = 0.0\n",
        "        TP_FN=0.0\n",
        "        TP=0.0\n",
        "        \n",
        "        num_correct=0.0\n",
        "        total_guesses=0.0\n",
        "        model.eval()\n",
        "        outs,tars=[],[]\n",
        "        for i, batch_data in enumerate(test_data_loader, 0):\n",
        "\n",
        "            inputs,meta_, labels = batch_data\n",
        "            #inputs[:,:,out_x,out_y]=0.0\n",
        "            labels=labels.type(torch.FloatTensor)\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            meta_ = meta_.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs,meta_)\n",
        "            outputs=outputs.squeeze(1)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            outputs= torch.sigmoid(outputs)\n",
        "            num_correct += torch.eq(torch.round(outputs), labels).sum().item()\n",
        "            total_guesses += inputs.size()[0] \n",
        "            v_running_loss += loss.item()\n",
        "\n",
        "            print('\\rValidating => Batch: {:d}/{:d}'.format((i+1),len(test_data_loader)),end='',flush=True)\n",
        "\n",
        "            for out_val,tar_val in zip(outputs,labels):\n",
        "                outs.append(out_val.detach().cpu())\n",
        "                tars.append(tar_val.detach().cpu())\n",
        "                if torch.round(out_val) == 1:\n",
        "                    TP_FN +=1\n",
        "                    if torch.round(tar_val) ==1:\n",
        "                        TP +=1\n",
        "\n",
        "        print('\\r',end='',flush=True)\n",
        "\n",
        "        v_acc=1.0*num_correct/total_guesses\n",
        "        v_running_loss/=(i+1)\n",
        "        \n",
        "        outs=np.asarray(outs)\n",
        "        tars=np.asarray(tars)\n",
        "        val_spec=roc_auc_score(tars,outs)\n",
        "        sensitivity=1.0*TP/TP_FN\n",
        "        \n",
        "        ## scheduler calling\n",
        "        scheduler.step(val_spec)\n",
        "        \n",
        "        if best_val_spec < val_spec:\n",
        "            best_val_spec=val_spec\n",
        "            best_model_dict=model.state_dict()\n",
        "            stop_patience=np.maximum(stop_patience,2)\n",
        "        else :\n",
        "            stop_patience -=1\n",
        "            if stop_patience ==0:\n",
        "                print('Val_loss: [{:.7f}], val_acc: [{:.7f}], sensitivity: [{:.7f}], roc: [{:.7f}], best roc: [{:.7f}]'.format(v_running_loss,v_acc,sensitivity,val_spec,best_val_spec))\n",
        "                print('early stopping !! as no increase in val_spec')\n",
        "                break\n",
        "        print('Val_loss: [{:.7f}], val_acc: [{:.7f}], sensitivity: [{:.7f}], roc: [{:.7f}], best roc: [{:.7f}]'.format(v_running_loss,v_acc,sensitivity,val_spec,best_val_spec))\n",
        "    #break  \n",
        "    ## saving best model after each fold  \n",
        "    model.load_state_dict(best_model_dict)  \n",
        "    torch.save(best_model_dict, model_name+'_'+str(img_size)+'x'+str(img_size)+'_Fold_'+str(itr_folds+1)+' _roc_%.7f'%(best_val_spec)+'_.pth')\n",
        "    print('****** Best ROC at fold: [{:d}] is : [{:.7f}] ******'.format(itr_folds+1,best_val_spec))\n",
        "    print('model saved!! for fold:{:d}'.format(int(itr_folds+1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1276 8135\n",
            "------------Running Fold no:  1 ------------\n",
            "Train Size : 47387  (nor: 24407 ,mel: 22980)  Test Size :  9411\n",
            "Time: [901.562]s, Epoch: [1/15], Batch: [2962/2962], Loss: [0.3666562], Acc: [0.8402093]\n",
            "Val_loss: [0.3460749], val_acc: [0.8602699], sensitivity: [0.4862579], roc: [0.8307207], best roc: [0.8307207]\n",
            "Time: [905.947]s, Epoch: [2/15], Batch: [2962/2962], Loss: [0.3571638], Acc: [0.8466457]\n",
            "Val_loss: [0.3577486], val_acc: [0.8493253], sensitivity: [0.4520270], roc: [0.8186834], best roc: [0.8307207]\n",
            "Time: [908.326]s, Epoch: [3/15], Batch: [2962/2962], Loss: [0.3500195], Acc: [0.8495790]\n",
            "Epoch     3: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Val_loss: [0.3174783], val_acc: [0.8842843], sensitivity: [0.6130593], roc: [0.8239053], best roc: [0.8307207]\n",
            "Time: [905.588]s, Epoch: [4/15], Batch: [2962/2962], Loss: [0.3377966], Acc: [0.8553823]\n",
            "Val_loss: [0.3301175], val_acc: [0.8690894], sensitivity: [0.5176565], roc: [0.8306049], best roc: [0.8307207]\n",
            "early stopping !! as no increase in val_spec\n",
            "****** Best ROC at fold: [1] is : [0.8307207] ******\n",
            "model saved!! for fold:1\n",
            "------------Running Fold no:  2 ------------\n",
            "Train Size : 47387  (nor: 24407 ,mel: 22980)  Test Size :  9411\n",
            "Time: [905.983]s, Epoch: [1/15], Batch: [2962/2962], Loss: [0.4221295], Acc: [0.8168274]\n",
            "Val_loss: [0.2373065], val_acc: [0.9118053], sensitivity: [0.6258465], roc: [0.9599484], best roc: [0.9599484]\n",
            "Time: [910.394]s, Epoch: [2/15], Batch: [2962/2962], Loss: [0.4069161], Acc: [0.8189377]\n",
            "Val_loss: [0.2373513], val_acc: [0.9123366], sensitivity: [0.6314869], roc: [0.9570318], best roc: [0.9599484]\n",
            "Time: [907.220]s, Epoch: [3/15], Batch: [2962/2962], Loss: [0.3989667], Acc: [0.8223141]\n",
            "Epoch     7: reducing learning rate of group 0 to 6.2500e-05.\n",
            "Val_loss: [0.2682409], val_acc: [0.8982042], sensitivity: [0.5835084], roc: [0.9553448], best roc: [0.9599484]\n",
            "Time: [912.658]s, Epoch: [4/15], Batch: [2962/2962], Loss: [0.4010011], Acc: [0.8203727]\n",
            "Val_loss: [0.2907982], val_acc: [0.8904473], sensitivity: [0.5603151], roc: [0.9539874], best roc: [0.9599484]\n",
            "early stopping !! as no increase in val_spec\n",
            "****** Best ROC at fold: [2] is : [0.9599484] ******\n",
            "model saved!! for fold:2\n",
            "------------Running Fold no:  3 ------------\n",
            "Train Size : 47387  (nor: 24407 ,mel: 22980)  Test Size :  9411\n",
            "Time: [907.428]s, Epoch: [1/15], Batch: [2962/2962], Loss: [0.4198487], Acc: [0.8094203]\n",
            "Val_loss: [0.2740000], val_acc: [0.8983105], sensitivity: [0.5748475], roc: [0.9801113], best roc: [0.9801113]\n",
            "Time: [913.487]s, Epoch: [2/15], Batch: [2962/2962], Loss: [0.4204117], Acc: [0.8109608]\n",
            "Val_loss: [0.2768692], val_acc: [0.8972479], sensitivity: [0.5724332], roc: [0.9798262], best roc: [0.9801113]\n",
            "Time: [954.240]s, Epoch: [3/15], Batch: [2962/2962], Loss: [0.4187953], Acc: [0.8124169]\n",
            "Epoch    11: reducing learning rate of group 0 to 6.2500e-06.\n",
            "Val_loss: [0.2833017], val_acc: [0.8952290], sensitivity: [0.5671296], roc: [0.9795142], best roc: [0.9801113]\n",
            "Time: [980.258]s, Epoch: [4/15], Batch: [2962/2962], Loss: [0.4132400], Acc: [0.8135776]\n",
            "Val_loss: [0.2542388], val_acc: [0.9107427], sensitivity: [0.6095477], roc: [0.9807433], best roc: [0.9807433]\n",
            "Time: [984.174]s, Epoch: [5/15], Batch: [2962/2962], Loss: [0.4181933], Acc: [0.8111507]\n",
            "Val_loss: [0.2615903], val_acc: [0.9056423], sensitivity: [0.5948192], roc: [0.9805163], best roc: [0.9807433]\n",
            "Time: [192.710]s, Epoch: [6/15], Batch: [570/2962], Loss: [0.4057905], Acc: [0.8184211]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-16471483660a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtotal_guesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmeta_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OchXpmUQ1O90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check=os.listdir('train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw-2XhwE1UW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c68e1c5-081a-4914-bd14-84542fcba3a2"
      },
      "source": [
        "for it in check:\n",
        "    if it == 'M_ISIC_1616031.jpg':\n",
        "        print('lol')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lol\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_q7zKYroYeb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f9f5245-23f6-458c-c5aa-0df18b8ca4a2"
      },
      "source": [
        "shutil.copy('/content/efficientnet-b3_300x300_Fold_5 _roc_0.9992506_.pth','/content/drive/My Drive/data_sets/Melanoma Data/ZipData/efficientnet-b3_300x300_Fold_5 _roc_0.9992506_.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/data_sets/Melanoma Data/ZipData/efficientnet-b3_300x300_Fold_5 _roc_0.9992506_.pth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbQWbUlt0CM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "655e051e-7d34-4b89-e2ce-f2247e96bba7"
      },
      "source": [
        "shutil.copy('/content/drive/My Drive/data_sets/Melanoma Data/ZipData/efficientnet-b3_300x300_Fold_4 _roc_0.9996615_.pth','/content/efficientnet-b3_300x300_Fold_4 _roc_0.9996615_.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/efficientnet-b3_300x300_Fold_4 _roc_0.9996615_.pth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CWlT_PMgp4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4eb4ffbb-47c7-4de7-8fab-84cd5fa8a34e"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/efficientnet-b3_300x300_Fold_4 _roc_0.9996615_.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fkExUFZqvCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4437b3cb-0aae-4b01-c129-970d19d97535"
      },
      "source": [
        "temp1=os.listdir('./')\n",
        "cnt=0\n",
        "for name in temp1:\n",
        "  if name[:3]=='eff':\n",
        "    cnt+=1\n",
        "    if cnt==3:\n",
        "      ##shutil.copy('./'+name,'/content/drive/My Drive/data_sets/Melanoma Data/ZipData/'+name)\n",
        "      print(name)\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "efficientnet-b3_300x300_Fold_1 _roc_0.9873713_.pth\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}